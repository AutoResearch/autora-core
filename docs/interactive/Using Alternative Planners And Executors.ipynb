{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom Planners and Executors\n",
    "\n",
    "By switching out the `executor_collection` and/or the `planner`, we can specify a\n",
    "different way of running the cycle.\n",
    "\n",
    "## Easier Seeding with a Smarter Planner\n",
    "\n",
    "In this example, we use the `Controller` which allows much more control over execution\n",
    "order. It considers the last available result and picks the matching next step. This means\n",
    "that seeding is relatively simple."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from autora.experimentalist.pipeline import make_pipeline\n",
    "from autora.variable import VariableCollection, Variable\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from autora.workflow import Controller\n",
    "from itertools import takewhile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ground_truth(x):\n",
    "    return x + 1\n",
    "variables = VariableCollection(\n",
    "   independent_variables=[Variable(name=\"x1\", allowed_values=range(11))],\n",
    "   dependent_variables=[Variable(name=\"y\", value_range=(-20, 20))],\n",
    "   )\n",
    "example_experimentalist = make_pipeline(\n",
    "    [variables.independent_variables[0].allowed_values])\n",
    "\n",
    "def get_example_synthetic_experiment_runner():\n",
    "    rng = np.random.default_rng(seed=180)\n",
    "    def runner(x):\n",
    "        return ground_truth(x) + rng.normal(0, 0.1, x.shape)\n",
    "    return runner\n",
    "\n",
    "example_synthetic_experiment_runner = get_example_synthetic_experiment_runner()\n",
    "\n",
    "example_theorist = LinearRegression()\n",
    "\n",
    "def monitor(state):\n",
    "    print(f\"MONITOR: Generated new {state.history[-1].kind}\")\n",
    "\n",
    "cycle_with_last_result_planner = Controller(\n",
    "    monitor=monitor,\n",
    "    variables=variables,\n",
    "    experimentalist=example_experimentalist,\n",
    "    experiment_runner=example_synthetic_experiment_runner,\n",
    "    theorist=example_theorist,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we run this cycle starting with no data, we generate an experimental condition first:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MONITOR: Generated new CONDITION\n",
      "MONITOR: Generated new OBSERVATION\n",
      "MONITOR: Generated new MODEL\n",
      "MONITOR: Generated new CONDITION\n",
      "MONITOR: Generated new OBSERVATION\n",
      "MONITOR: Generated new MODEL\n"
     ]
    }
   ],
   "source": [
    "_ = list(takewhile(lambda c: len(c.state.models) < 2, cycle_with_last_result_planner))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, if we seed the same cycle with observations, then its first Executor will be the theorist:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "controller_with_seed_observation = Controller(\n",
    "    monitor=monitor,\n",
    "    variables=variables,\n",
    "    theorist=example_theorist,\n",
    "    experimentalist=example_experimentalist,\n",
    "    experiment_runner=example_synthetic_experiment_runner,\n",
    ")\n",
    "seed_observation = example_synthetic_experiment_runner(np.linspace(0,5,10))\n",
    "controller_with_seed_observation.seed(observations=[seed_observation])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MONITOR: Generated new MODEL\n"
     ]
    }
   ],
   "source": [
    "_ = next(controller_with_seed_observation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Arbitrary Execution Order (Toy Example)\n",
    "\n",
    "In some cases, we need to change the order of execution of different steps completely. This might be\n",
    " useful in cases when different experimentalists or theorists are needed at different times in\n",
    " the cycle, e.g. for initial seeding, or if the _order_ of execution is the subject of the\n",
    " experiment.\n",
    "\n",
    "In this example, we use a planner which suggests a different random operation at each\n",
    "step, demonstrating arbitrary execution order. We do this by modifying the planner attribute\n",
    "of an existing controller\n",
    "\n",
    "This might be useful in cases when different experimentalists or theorists are needed at\n",
    "different times in the cycle, e.g. for initial seeding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autora.workflow.planner import random_operation_planner\n",
    "def monitor(state):\n",
    "    print(f\"MONITOR: Generated new {state.history[-1].kind}\")\n",
    "controller_with_random_planner = Controller(\n",
    "    planner=random_operation_planner,\n",
    "    monitor=monitor,\n",
    "    variables=variables,\n",
    "    theorist=example_theorist,\n",
    "    experimentalist=example_experimentalist,\n",
    "    experiment_runner=example_synthetic_experiment_runner,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `random_operation_planner` depends on the python random number generator, so we seed it first:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import seed\n",
    "seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also want to watch the logging messages from the cycle:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import sys\n",
    "logging.basicConfig(format='%(levelname)s: %(message)s', stream=sys.stdout,\n",
    "    level=logging.INFO)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can evaluate the cycle and watch its behaviour:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def step(controller_):\n",
    "    try:\n",
    "        _ = next(controller_)\n",
    "    except Exception as e:\n",
    "        print(f\"FAILED: with {e=}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step, the theorist is selected as the random Executor, and it fails because it\n",
    "depends on there being observations to theorize against:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: getting step_name='theorist'\n",
      "INFO: running next_function=<function from_theorist_estimator.<locals>._executor_theorist at 0x14f594dc0>\n",
      "FAILED: with e=AssertionError('observations=[] needs at least one entry for model fitting')\n"
     ]
    }
   ],
   "source": [
    "step(controller_with_random_planner) # i = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second step, a new condition is generated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: getting step_name='experimentalist'\n",
      "INFO: running next_function=<function from_experimentalist_pipeline.<locals>._executor_experimentalist at 0x14f594dc0>\n",
      "MONITOR: Generated new CONDITION\n"
     ]
    }
   ],
   "source": [
    "step(controller_with_random_planner) # i = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... which is repeated on the third step as well:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: getting step_name='experimentalist'\n",
      "INFO: running next_function=<function from_experimentalist_pipeline.<locals>._executor_experimentalist at 0x14f595750>\n",
      "MONITOR: Generated new CONDITION\n"
     ]
    }
   ],
   "source": [
    "step(controller_with_random_planner) # i = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On the fourth step, we generate another error when trying to run the theorist:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: getting step_name='theorist'\n",
      "INFO: running next_function=<function from_theorist_estimator.<locals>._executor_theorist at 0x14f5955a0>\n",
      "FAILED: with e=AssertionError('observations=[] needs at least one entry for model fitting')\n"
     ]
    }
   ],
   "source": [
    "step(controller_with_random_planner) # i = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On the fifth step, we generate a first real observation, so that the next time we try to run\n",
    "a theorist we are successful:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: getting step_name='experiment_runner'\n",
      "INFO: running next_function=<function from_experiment_runner_callable.<locals>._executor_experiment_runner at 0x107119630>\n",
      "MONITOR: Generated new OBSERVATION\n"
     ]
    }
   ],
   "source": [
    "step(controller_with_random_planner) # i = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By the ninth iteration, there are observations which the theorist can use, and it succeeds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: getting step_name='experimentalist'\n",
      "INFO: running next_function=<function from_experimentalist_pipeline.<locals>._executor_experimentalist at 0x14f596200>\n",
      "MONITOR: Generated new CONDITION\n",
      "INFO: getting step_name='experimentalist'\n",
      "INFO: running next_function=<function from_experimentalist_pipeline.<locals>._executor_experimentalist at 0x1071195a0>\n",
      "MONITOR: Generated new CONDITION\n",
      "INFO: getting step_name='experimentalist'\n",
      "INFO: running next_function=<function from_experimentalist_pipeline.<locals>._executor_experimentalist at 0x14f5964d0>\n",
      "MONITOR: Generated new CONDITION\n",
      "INFO: getting step_name='theorist'\n",
      "INFO: running next_function=<function from_theorist_estimator.<locals>._executor_theorist at 0x14f596830>\n",
      "MONITOR: Generated new MODEL\n"
     ]
    }
   ],
   "source": [
    "_ = list(takewhile(lambda c: len(c.state.models) < 1, controller_with_random_planner))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Arbitrary Executors and Planners\n",
    "\n",
    "In some cases, we need to go beyond adding different orders of planning the three\n",
    "`experimentalist`, `experiment_runner` and `theorist` and build more complex cycles with\n",
    "different Executors for different states.\n",
    "\n",
    "For instance, there might be a situation where at the start, the main \"active\" experimentalist\n",
    "can't be run as it needs one or more models as input.\n",
    "Once there are at least two models, then the active experimentalist _can_ be run.\n",
    "One method to handle this is to run a \"seed\" experimentalist until the main experimentalist can\n",
    "be used.\n",
    "\n",
    "In these cases, we need full control over (and have full responsibility for) the planners and\n",
    "executors.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model we'll try to discover is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ground_truth(x, m=3.5, c=1):\n",
    "    return m * x + c\n",
    "rng = np.random.default_rng(seed=180)\n",
    "def experiment_runner(x):\n",
    "    return ground_truth(x) + rng.normal(0, 0.1)\n",
    "variables = VariableCollection(\n",
    "   independent_variables=[Variable(name=\"x1\", value_range=(-10, 10))],\n",
    "   dependent_variables=[Variable(name=\"y\", value_range=(-100, 100))],\n",
    "   )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now define a planner which chooses a different experimentalist when supplied with no data\n",
    "versus some data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autora.workflow.planner import last_result_kind_planner\n",
    "from autora.workflow.state import History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seeding_planner(state):\n",
    "    # We're going to reuse the \"last_result_kind_planner\" planner, and modify its output.\n",
    "    next_function = last_result_kind_planner(state)\n",
    "    if next_function == \"experimentalist\":\n",
    "        if len(state.models) >= 2:\n",
    "            return \"main_experimentalist\"\n",
    "        else:\n",
    "            return \"seed_experimentalist\"\n",
    "    else:\n",
    "        return next_function\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can see what would happen with a particular state. If there are no results, then we get the seed experimentalist:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'seed_experimentalist'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seeding_planner(History())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... and we also get the seed experimentalist if the last result was a model and there are less than two models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'seed_experimentalist'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seeding_planner(History(models=['a single model']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "whereas if we have at least two models to work on, we get the main experimentalist:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'main_experimentalist'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seeding_planner(History(models=['a model', 'another model']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we had a condition last, we choose the experiment runner next:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'experiment_runner'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seeding_planner(History(conditions=['a condition']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we had an observation last, we choose the theorist next:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'theorist'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seeding_planner(History(observations=['an observation']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to define an executor collection to handle the actual execution steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autora.experimentalist.pipeline import make_pipeline, Pipeline\n",
    "from autora.experimentalist.sampler.random_sampler import random_sampler\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wen can run the seed pipeline with no data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 6.71671672, -0.73073073, -5.05505506,  6.13613614,  0.03003003,\n",
       "        4.59459459,  2.79279279,  5.43543544, -1.65165165,  8.0980981 ])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experimentalist_which_needs_no_data = make_pipeline([\n",
    "    np.linspace(*variables.independent_variables[0].value_range, 1_000),\n",
    "    partial(random_sampler, n=10)]\n",
    ")\n",
    "np.array(experimentalist_which_needs_no_data())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... whereas we need some model for this sampler:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "model_disagreement_sampler() missing 1 required positional argument: 'models'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mautora\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexperimentalist\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msampler\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_disagreement\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m model_disagreement_sampler\n\u001b[1;32m      2\u001b[0m experimentalist_which_needs_a_model \u001b[38;5;241m=\u001b[39m Pipeline([\n\u001b[1;32m      3\u001b[0m     (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpool\u001b[39m\u001b[38;5;124m'\u001b[39m, np\u001b[38;5;241m.\u001b[39mlinspace(\u001b[38;5;241m*\u001b[39mvariables\u001b[38;5;241m.\u001b[39mindependent_variables[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mvalue_range, \u001b[38;5;241m1_000\u001b[39m)),\n\u001b[1;32m      4\u001b[0m     (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msampler\u001b[39m\u001b[38;5;124m'\u001b[39m, partial(model_disagreement_sampler, num_samples\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m)),])\n\u001b[0;32m----> 5\u001b[0m \u001b[43mexperimentalist_which_needs_a_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Developer/autora-workflow/venv/lib/python3.10/site-packages/autora/experimentalist/pipeline.py:171\u001b[0m, in \u001b[0;36mPipeline.__call__\u001b[0;34m(self, ex, **params)\u001b[0m\n\u001b[1;32m    169\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(pipe, Pipe)\n\u001b[1;32m    170\u001b[0m     all_params_for_pipe \u001b[38;5;241m=\u001b[39m merged_params\u001b[38;5;241m.\u001b[39mget(name, \u001b[38;5;28mdict\u001b[39m())\n\u001b[0;32m--> 171\u001b[0m     results\u001b[38;5;241m.\u001b[39mappend(\u001b[43mpipe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresults\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mall_params_for_pipe\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    173\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m results[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n",
      "\u001b[0;31mTypeError\u001b[0m: model_disagreement_sampler() missing 1 required positional argument: 'models'"
     ]
    }
   ],
   "source": [
    "from autora.experimentalist.sampler.model_disagreement import model_disagreement_sampler\n",
    "experimentalist_which_needs_a_model = Pipeline([\n",
    "    ('pool', np.linspace(*variables.independent_variables[0].value_range, 1_000)),\n",
    "    ('sampler', partial(model_disagreement_sampler, num_samples=5)),])\n",
    "experimentalist_which_needs_a_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll have to provide the models during the cycle run.\n",
    "\n",
    "We need a reasonable theorist for this situation. For this problem, a linear regressor will suffice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = LinearRegression()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test the theorist for the ideal case – lots of data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'m = 3.50, c = 1.04'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.linspace(*variables.independent_variables[0].value_range, 1_000).reshape(-1, 1)\n",
    "tfitted = t.fit(X, experiment_runner(X))\n",
    "f\"m = {tfitted.coef_[0][0]:.2f}, c = {tfitted.intercept_[0]:.2f}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This seems to work fine.\n",
    "\n",
    "Now we can define the executor component. We'll use a factory method to generate the\n",
    "    collection:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autora.workflow.executor import (ChainedFunctionMapping, from_experimentalist_pipeline,\n",
    "    from_experiment_runner_callable, from_theorist_estimator)\n",
    "executor_collection = ChainedFunctionMapping(\n",
    "    seed_experimentalist=\n",
    "        [from_experimentalist_pipeline, experimentalist_which_needs_no_data],\n",
    "    main_experimentalist=\n",
    "        [from_experimentalist_pipeline, experimentalist_which_needs_a_model],\n",
    "    experiment_runner=[from_experiment_runner_callable, experiment_runner],\n",
    "    theorist=[from_theorist_estimator, LinearRegression()],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need some special parameters to handle the main experimentalist, so we specify those:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\"main_experimentalist\": {\"sampler\": {\"models\": \"%models%\"}}}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now instantiate the controller:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<autora.workflow.base.BaseController at 0x14f8ed570>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from autora.workflow.base import BaseController\n",
    "from autora.workflow.state import History\n",
    "c = BaseController(\n",
    "        state=History(variables=variables, params=params),\n",
    "        planner=seeding_planner,\n",
    "        executor_collection=executor_collection\n",
    ")\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PrintHandler(logging.Handler):\n",
    "    def emit(self, record):\n",
    "        print(self.format(record))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On the first step, we generate a condition sampled randomly across the whole domain (as we\n",
    "expected):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: getting step_name='seed_experimentalist'\n",
      "INFO: running next_function=<function from_experimentalist_pipeline.<locals>._executor_experimentalist at 0x14f85feb0>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Result(data=array([ 9.4994995 , -8.17817818, -1.19119119,  8.6986987 ,  7.45745746,\n",
       "       -6.93693694,  8.05805806, -1.45145145, -5.97597598,  1.57157157]), kind=ResultKind.CONDITION)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(c).state.history[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After three more steps, we generate a new condition, which again is sampled across the whole domain. Here we iterate\n",
    "the controller until we've got two sets of conditions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: getting step_name='experiment_runner'\n",
      "INFO: running next_function=<function from_experiment_runner_callable.<locals>._executor_experiment_runner at 0x14f85fe20>\n",
      "INFO: getting step_name='theorist'\n",
      "INFO: running next_function=<function from_theorist_estimator.<locals>._executor_theorist at 0x107118b80>\n",
      "INFO: getting step_name='seed_experimentalist'\n",
      "INFO: running next_function=<function from_experimentalist_pipeline.<locals>._executor_experimentalist at 0x14f85fe20>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Result(data=array([ 1.57157157, -3.93393393, -0.47047047, -4.47447447,  8.43843844,\n",
       "        6.17617618, -3.49349349, -8.998999  ,  4.93493493,  2.25225225]), kind=ResultKind.CONDITION)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_ = list(takewhile(lambda c: len(c.state.conditions) < 2, c))\n",
    "c.state.history[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have two models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: getting step_name='experiment_runner'\n",
      "INFO: running next_function=<function from_experiment_runner_callable.<locals>._executor_experiment_runner at 0x14f85f9a0>\n",
      "INFO: getting step_name='theorist'\n",
      "INFO: running next_function=<function from_theorist_estimator.<locals>._executor_theorist at 0x107118b80>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[LinearRegression(), LinearRegression()]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_ = list(takewhile(lambda c: len(c.state.models) < 2, c))\n",
    "c.state.models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... when we run the next step, we'll get the main experimentalist. This samples five points from the extreme\n",
    "parts  of the problem domain where the disagreement between the two models is the greatest:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: getting step_name='main_experimentalist'\n",
      "INFO: running next_function=<function from_experimentalist_pipeline.<locals>._executor_experimentalist at 0x14f85f9a0>\n",
      "WARNING: new_conditions=array([-10.        ,  -9.97997998,  -9.95995996,  -9.93993994,\n",
      "        -9.91991992]) is an ndarray, so variable confusion is a possibility\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Result(data=array([-10.        ,  -9.97997998,  -9.95995996,  -9.93993994,\n",
       "        -9.91991992]), kind=ResultKind.CONDITION)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(c).state.history[-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
