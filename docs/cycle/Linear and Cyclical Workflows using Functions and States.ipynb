{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear And Cyclical Workflows Using Functions And States"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the functions in `autora.workflow`, we can build flexible pipelines and cycles which operate on state objects.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "from dataclasses import field, dataclass\n",
    "\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "from autora.state.delta import State, Delta, wrap_to_use_state\n",
    "from autora.state.wrapper import theorist_from_estimator, experiment_runner_from_x_to_y_function\n",
    "from autora.variable import VariableCollection, Variable\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment Runner And Theorist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define a two part AER pipeline consisting of an experiment runner and a theorist (we use the seed conditions\n",
    "always).\n",
    "\n",
    "The key part here is that both experiment runner and theorist are functions which:\n",
    "- operate on the `State`, and\n",
    "- return a modified object of the **same type** `State`.\n",
    "\n",
    "### Defining The State\n",
    "\n",
    "We define the state as a dataclass, subclassed from `autora.workflow.State` with fields representing the variables,\n",
    "parameters, experimental data, (possibly) conditions, and (possibly) a model.\n",
    "\n",
    "This state has no \"history\"; it represents a snapshot of the data at one time. Other exemplar state objects are\n",
    "available in the subpackage `autora.workflow.state` and include some with in-built histories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass(frozen=True)\n",
    "class Snapshot(State):\n",
    "    variables: VariableCollection = field(metadata={\"delta\": \"replace\"})\n",
    "    params: dict = field(metadata={\"delta\": \"replace\"})\n",
    "    experiment_data: pd.DataFrame = field(metadata={\"delta\": \"extend\"})\n",
    "    conditions: pd.Series = field(default=None, metadata={\"delta\": \"replace\"})\n",
    "    model: Optional[BaseEstimator] = field(default=None, metadata={\"delta\": \"replace\"})\n",
    "\n",
    "s = Snapshot(\n",
    "    variables=VariableCollection(independent_variables=[Variable(\"x\", value_range=(-15,15))],\n",
    "                                 dependent_variables=[Variable(\"y\")]),\n",
    "    params={},\n",
    "    conditions=pd.DataFrame({\"x\": np.linspace(-15,15,101)}),\n",
    "    experiment_data = pd.DataFrame(columns=[\"x\",\"y\"]),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining The Experiment Runner\n",
    "\n",
    "For this example, we'll use a polynomial of degree 3 as our \"ground truth\" function. We're also using pandas\n",
    "DataFrames and Series as our data interchange format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coefs = [432, -144, -3, 1] # from https://www.maa.org/sites/default/files/0025570x28304.di021116.02p0130a.pdf\n",
    "\n",
    "def ground_truth(x: pd.Series) -> pd.Series:\n",
    "    y = pd.Series(coefs[0] + coefs[1] * x + coefs[2] * x**2 + coefs[3] * x**3, name=\"y\")\n",
    "    return y\n",
    "\n",
    "def noisy_observation(x: pd.Series, std=1000, rng=None) -> pd.Series:\n",
    "    if rng is None:\n",
    "        rng = np.random.default_rng()\n",
    "    y = ground_truth(x) + rng.normal(0, std, len(x))\n",
    "    return y\n",
    "\n",
    "def noisy_observation_df(df: pd.DataFrame, std=1000, rng=None) -> pd.DataFrame:\n",
    "    y = pd.DataFrame({\"y\": noisy_observation(df[\"x\"], std=std, rng=rng)})    \n",
    "    return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given this state, we define a two part AER pipeline consisting of an experiment runner and a theorist. We'll just\n",
    "reuse the initial seed `conditions` in this example.\n",
    "\n",
    "First we define and test the experiment runner.\n",
    "\n",
    "The key part here is that both the experiment runner and the theorist are functions which operate on the `State`. Therefore, we use a wrapper function `experiment_runner_from_x_to_y_function` that wraps the previously defined `noisy_observation_df` function and returns a function with the same functionality, but operating on the `State`. In this case, we want to use the `State` field `conditions` as input and extend the `State` field `experiment_data`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_runner = experiment_runner_from_x_to_y_function(noisy_observation_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we run the experiment runner, we can see the updated state object which is returned – it has new experimental data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_runner(s, std=1).experiment_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining The Theorist\n",
    "\n",
    "Now we define a theorist, which does a linear regression on the polynomial of degree 5. We define a regressor and a\n",
    "method to return its feature names and coefficients, and then the theorist to handle it. Here, we use a different wrapper `theorist_from_estimator` that wraps the regressor and returns a function with the same functionality, but operating on `State` fields. In this case, we want to use the `State` field `experiment_data` and extend the `State` field `models`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Completely standard scikit-learn pipeline regressor\n",
    "regressor = make_pipeline(PolynomialFeatures(degree=5), LinearRegression())\n",
    "theorist = theorist_from_estimator(regressor)\n",
    "\n",
    "def get_equation(r):\n",
    "    t = r.named_steps['polynomialfeatures'].get_feature_names_out()\n",
    "    c = r.named_steps['linearregression'].coef_\n",
    "    return pd.DataFrame({\"t\": t, \"coefficient\": c.reshape(t.shape)})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Directly Chaining State Based Functions\n",
    "\n",
    "Now we run the theorist on the result of the experiment_runner (by chaining the two functions)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = theorist(experiment_runner(s, rng=np.random.default_rng(1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The fitted coefficients are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_equation(t.model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating A Pipeline With State Based Functions\n",
    "\n",
    "Now we can define the simplest pipeline which runs the experiment runner and theorist in sequence and returns the\n",
    "updated state:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline(state: State, rng=None) -> State:\n",
    "    s_ = state\n",
    "    t_ = experiment_runner(s_, rng=rng)\n",
    "    u_ = theorist(t_)\n",
    "    return u_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running this pipeline is the same as running the individual steps – just pass the state object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u = pipeline(s, rng=np.random.default_rng(1))\n",
    "get_equation(u.model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the pipeline function operates on the `State` itself and returns a `State`, we can chain these pipelines in the same fashion as we chain the theorist and experiment_runner:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u_ = pipeline(pipeline(s, rng=np.random.default_rng(1)))\n",
    "get_equation(u_.model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To show what's happening, we'll show the data, best fit model and ground truth:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_best_fit(state):\n",
    "    state.experiment_data.plot.scatter(\"x\", \"y\", s=1, alpha=0.5, c=\"gray\")\n",
    "\n",
    "    observed_x = state.experiment_data[[\"x\"]].sort_values(by=\"x\")\n",
    "    observed_x = pd.DataFrame({\"x\": np.linspace(observed_x[\"x\"].min(), observed_x[\"x\"].max(), 101)})\n",
    "\n",
    "    plt.plot(observed_x, state.model.predict(observed_x), label=\"best fit\")\n",
    "    \n",
    "    allowed_x = pd.Series(np.linspace(*state.variables.independent_variables[0].value_range, 101), name=\"x\")\n",
    "    plt.plot(allowed_x, ground_truth(allowed_x), label=\"ground truth\")\n",
    "    \n",
    "    plt.legend()\n",
    "\n",
    "def show_coefficients(state):\n",
    "    return get_equation(state.model)\n",
    "\n",
    "show_best_fit(u)\n",
    "show_coefficients(u)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use this pipeline to make a trivial cycle, where we keep on gathering data until we reach 1000 datapoints. Any\n",
    " condition defined on the state object could be used here, though."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = s\n",
    "while len(v.experiment_data) < 1_000:  # any condition on the state can be used here.\n",
    "    v = pipeline(v)\n",
    "show_best_fit(v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Generators With State Based Functions\n",
    "\n",
    "We can redefine the pipeline as a generator, which can be operated on using iteration tools:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cycle(state: State) -> State:\n",
    "    s_ = state\n",
    "    while True:\n",
    "        s_ = experiment_runner(s_)\n",
    "        s_ = theorist(s_)\n",
    "        yield s_\n",
    "\n",
    "cycle_generator = cycle(s)\n",
    "\n",
    "for i in range(1000):\n",
    "    t = next(cycle_generator)\n",
    "show_best_fit(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also define a cycle (or a sequence of steps) which yield the intermediate results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v0 = s\n",
    "def cycle(state: State) -> State:\n",
    "    s_ = state\n",
    "    while True:\n",
    "        print(\"#-- running experiment_runner --#\\n\")\n",
    "        s_ = experiment_runner(s_)\n",
    "        yield s_\n",
    "        print(\"#-- running theorist --#\\n\")\n",
    "        s_ = theorist(s_)\n",
    "        yield s_\n",
    "\n",
    "cycle_generator = cycle(v0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At the outset, we have no model and an emtpy experiment_data dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"{v0.model=}, \\n{v0.experiment_data.shape=}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the first `next`, we only run the \"experiment_runner\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v1 = next(cycle_generator)\n",
    "print(f\"{v1.model=}, \\n{v1.experiment_data.shape=}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next step, we run the theorist on that data, but we don't add any new data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v2 = next(cycle_generator)\n",
    "print(f\"{v2.model=}, \\n{v2.experiment_data.shape=}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next step, we run the experiment runner again and gather more observations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v3 = next(cycle_generator)\n",
    "print(f\"{v3.model=}, \\n{v3.experiment_data.shape=}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding The Experimentalist\n",
    "Modifying the code to use a custom experimentalist is simple.\n",
    "We define an experimentalist which adds four observations each cycle:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experimentalist_rng = np.random.default_rng(180)\n",
    "@wrap_to_use_state\n",
    "\n",
    "def experimentalist(variables: VariableCollection, n_samples=1):\n",
    "    names = [v.name for v in variables.independent_variables]\n",
    "    low = [v.value_range[0] for v in variables.independent_variables]\n",
    "    high = [v.value_range[1] for v in variables.independent_variables]\n",
    "    x_range = experimentalist_rng.uniform(low, high, size=n_samples)\n",
    "    conditions = pd.DataFrame({\"x\": x_range})\n",
    "    return Delta(conditions=conditions)\n",
    "\n",
    "experimentalist(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u0 = s\n",
    "for i in range(5):\n",
    "    u0 = experimentalist(u0, n_samples=10)\n",
    "    u0 = experiment_runner(u0)\n",
    "    u0 = theorist(u0)\n",
    "    show_best_fit(u0)\n",
    "    plt.title(f\"{i=}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
