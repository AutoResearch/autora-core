{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Cycle\n",
    "This cycle uses mixture experimentalist, BMS theorist, and equation sampler as a source for the ground truth. "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b5f4e05f1a809942"
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [],
   "source": [
    "import copy\n",
    "from dataclasses import dataclass, field\n",
    "from typing import List\n",
    "\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import numpy as np\n",
    "import math\n",
    "import pandas as pd\n",
    "from autora.variable import VariableCollection, Variable\n",
    "from autora.state.standard import StandardState\n",
    "from autora.state import on_state\n",
    "from autora.state.wrapper import state_fn_from_estimator\n",
    "from autora.theorist.bms import BMSRegressor\n",
    "from equation_tree import sample \n",
    "from equation_tree.tree import instantiate_constants\n",
    "from equation_tree.prior import DEFAULT_PRIOR_FUNCTIONS, DEFAULT_PRIOR_OPERATORS, \\\n",
    "    structure_prior_from_max_depth\n",
    "import pprint\n",
    "from autora.experiment_runner.synthetic.abstract.equation import equation_experiment\n",
    "from autora.experimentalist.mixture import sample as mixture_sample\n",
    "from autora.experimentalist.grid_ import grid_pool\n",
    "from autora.experimentalist.random_ import random_sample, random_pool\n",
    "from autora.state import Delta\n",
    "from autora.experimentalist.falsification import falsification_score_sample\n",
    "from autora.experimentalist.model_disagreement import model_disagreement_score_sample\n",
    "from autora.experimentalist.novelty import novelty_score_sample"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-18T21:21:04.586860Z",
     "start_time": "2023-08-18T21:20:58.879962Z"
    }
   },
   "id": "aae58e596d506fd5"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "# SAMPLING\n",
    "N_CONDITIONS = 50000\n",
    "TEMPERATURE = 1.\n",
    "WEIGHTS = {'falsification':[.1, .1], 'novelty':[.5, .5]}\n",
    "NUM_SAMPLES = 100\n",
    "POOL_RANGE = 10\n",
    "\n",
    "# EQUATION\n",
    "MAX_TREE_DEPTH = 6\n",
    "MAX_NUM_VARIABLES = 4\n",
    "NUM_POOL_SAMPLES = 10_000\n",
    "CONSTANT_SIZE = 5"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-18T21:21:04.601856Z",
     "start_time": "2023-08-18T21:21:04.589269Z"
    }
   },
   "id": "7c265bc12bf17cde"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Ground truth\n",
    "Sampling the ground truth for this simulation."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f3a6feea4a22cbdc"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'[0, 1, 1, 2, 2, 3]': 0.027777777777777776,\n",
      " '[0, 1, 1, 2, 2]': 0.027777777777777776,\n",
      " '[0, 1, 1, 2, 3, 2]': 0.027777777777777776,\n",
      " '[0, 1, 1, 2, 3, 3]': 0.027777777777777776,\n",
      " '[0, 1, 1, 2, 3, 4]': 0.027777777777777776,\n",
      " '[0, 1, 1, 2, 3]': 0.027777777777777776,\n",
      " '[0, 1, 1, 2]': 0.027777777777777776,\n",
      " '[0, 1, 1]': 0.027777777777777776,\n",
      " '[0, 1, 2, 1, 2, 2]': 0.027777777777777776,\n",
      " '[0, 1, 2, 1, 2, 3]': 0.027777777777777776,\n",
      " '[0, 1, 2, 1, 2]': 0.027777777777777776,\n",
      " '[0, 1, 2, 1]': 0.027777777777777776,\n",
      " '[0, 1, 2, 2, 1, 2]': 0.027777777777777776,\n",
      " '[0, 1, 2, 2, 1]': 0.027777777777777776,\n",
      " '[0, 1, 2, 2, 3, 1]': 0.027777777777777776,\n",
      " '[0, 1, 2, 2, 3, 3]': 0.027777777777777776,\n",
      " '[0, 1, 2, 2, 3, 4]': 0.027777777777777776,\n",
      " '[0, 1, 2, 2, 3]': 0.027777777777777776,\n",
      " '[0, 1, 2, 2]': 0.027777777777777776,\n",
      " '[0, 1, 2, 3, 1, 2]': 0.027777777777777776,\n",
      " '[0, 1, 2, 3, 1]': 0.027777777777777776,\n",
      " '[0, 1, 2, 3, 2, 1]': 0.027777777777777776,\n",
      " '[0, 1, 2, 3, 2, 3]': 0.027777777777777776,\n",
      " '[0, 1, 2, 3, 2]': 0.027777777777777776,\n",
      " '[0, 1, 2, 3, 3, 1]': 0.027777777777777776,\n",
      " '[0, 1, 2, 3, 3, 2]': 0.027777777777777776,\n",
      " '[0, 1, 2, 3, 3, 4]': 0.027777777777777776,\n",
      " '[0, 1, 2, 3, 3]': 0.027777777777777776,\n",
      " '[0, 1, 2, 3, 4, 1]': 0.027777777777777776,\n",
      " '[0, 1, 2, 3, 4, 2]': 0.027777777777777776,\n",
      " '[0, 1, 2, 3, 4, 3]': 0.027777777777777776,\n",
      " '[0, 1, 2, 3, 4, 4]': 0.027777777777777776,\n",
      " '[0, 1, 2, 3, 4, 5]': 0.027777777777777776,\n",
      " '[0, 1, 2, 3, 4]': 0.027777777777777776,\n",
      " '[0, 1, 2, 3]': 0.027777777777777776,\n",
      " '[0, 1, 2]': 0.027777777777777776}\n",
      "{'abs': 0.14285714285714285,\n",
      " 'cos': 0.14285714285714285,\n",
      " 'exp': 0.14285714285714285,\n",
      " 'log': 0.14285714285714285,\n",
      " 'sin': 0.14285714285714285,\n",
      " 'sqrt': 0.14285714285714285,\n",
      " 'tan': 0.14285714285714285}\n",
      "{'*': 0.2, '+': 0.2, '-': 0.2, '/': 0.2, '^': 0.2}\n"
     ]
    }
   ],
   "source": [
    "structure_prior = structure_prior_from_max_depth(MAX_TREE_DEPTH)\n",
    "pprint.pprint(structure_prior)\n",
    "pprint.pprint(DEFAULT_PRIOR_FUNCTIONS)\n",
    "pprint.pprint(DEFAULT_PRIOR_OPERATORS)\n",
    "feature_prior = {'constants': .3, 'variables': .7}\n",
    "prior = {'functions': DEFAULT_PRIOR_FUNCTIONS, 'operators': DEFAULT_PRIOR_OPERATORS, 'structures': structure_prior, 'features': feature_prior}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-18T21:21:51.585749Z",
     "start_time": "2023-08-18T21:21:10.973462Z"
    }
   },
   "id": "80b8e511eb8fdd7"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: 100%|██████████| 1/1 [00:00<00:00, 32.61iteration/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": "exp(sin(x_1**exp(x_1)))",
      "text/latex": "$\\displaystyle e^{\\sin{\\left(x_{1}^{e^{x_{1}}} \\right)}}$"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "equation_raw = sample(n=1, prior=prior, max_num_variables=MAX_NUM_VARIABLES)\n",
    "equation_raw[0].sympy_expr"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-18T21:21:52.084471Z",
     "start_time": "2023-08-18T21:21:51.579178Z"
    }
   },
   "id": "6c8c756e3751846"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "exp(sin(x_1**exp(x_1)))",
      "text/latex": "$\\displaystyle e^{\\sin{\\left(x_{1}^{e^{x_{1}}} \\right)}}$"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "equation = instantiate_constants(equation_raw[0], lambda: np.random.rand()*CONSTANT_SIZE)\n",
    "equation.sympy_expr\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-18T21:21:52.107623Z",
     "start_time": "2023-08-18T21:21:52.092167Z"
    }
   },
   "id": "a3e2a152c68efb47"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Defining the metadata based on the sampled ground truth."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "864f712c69755491"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "independent_variables = []\n",
    "for v in range(equation.n_variables_unique):\n",
    "    independent_variables.append(Variable(equation.variables_unique[v],value_range=(-POOL_RANGE, POOL_RANGE)))\n",
    "\n",
    "variables=VariableCollection(\n",
    "        independent_variables=independent_variables,\n",
    "        dependent_variables=[Variable(\"y\")]\n",
    "    )"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-18T21:21:52.122568Z",
     "start_time": "2023-08-18T21:21:52.104532Z"
    }
   },
   "id": "7665db3926d7533"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Defining experiment runner from the equation and the variable collection"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "56c012f0ee045e7c"
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "experiment = equation_experiment(equation.sympy_expr, variables.independent_variables, variables.dependent_variables[0], rename_output_columns=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-18T21:21:52.159996Z",
     "start_time": "2023-08-18T21:21:52.116017Z"
    }
   },
   "id": "69c883bd50d1281"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Defining the state\n",
    "We can define an initial state for our discovery problem based on the variable specification above. Wrapping experiment runner into the state."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8c1633ff8518b07e"
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "@dataclass(frozen=True)\n",
    "class ExtendedState(StandardState):\n",
    "    models_bms: List[BaseEstimator] = field(\n",
    "        default_factory=list,\n",
    "        metadata={\"delta\": \"extend\"},\n",
    "    )\n",
    "    models_linear: List[BaseEstimator] = field(\n",
    "        default_factory=list,\n",
    "        metadata={\"delta\": \"extend\"},\n",
    "    )\n",
    "    models_polynom: List[BaseEstimator] = field(\n",
    "        default_factory=list,\n",
    "        metadata={\"delta\": \"extend\"},\n",
    "    )\n",
    "    rejections: List[int] = field(\n",
    "        default_factory=list,\n",
    "        metadata={\"delta\": \"extend\"},\n",
    "    )\n",
    "\n",
    "state = ExtendedState(\n",
    "    variables=variables\n",
    ")\n",
    "runner_on_state = on_state(experiment.experiment_runner, output=[\"experiment_data\"])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-18T21:21:52.160456Z",
     "start_time": "2023-08-18T21:21:52.136520Z"
    }
   },
   "id": "5ffb8b8592774cce"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Pooler"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "dad025cec3e1d7c3"
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [],
   "source": [
    "@on_state()\n",
    "def experimentalist_pooler(variables, equation):\n",
    "    conditions_ = pd.DataFrame(columns=[v.name for v in variables.independent_variables])\n",
    "    i = 0\n",
    "    while i < 1_000_000 and len(conditions_.index) < NUM_POOL_SAMPLES:\n",
    "        _sample = random_pool(variables, 1)\n",
    "        evaluation = equation.evaluate(_sample)\n",
    "        if np.isnan(evaluation).any() or np.isinf(evaluation).any():\n",
    "            i+=1\n",
    "            continue\n",
    "        conditions_.append(_sample, ignore_index=True)\n",
    "    if i >= 1_000_000:\n",
    "        return None\n",
    "    return Delta(conditions=conditions_, rejections=i)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Mixture experimentalist\n",
    "Defining the mixture experimentalist and wrapping it into the state"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b7f3d11dc9b0cf8d"
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Mixture Experimentalist Sampler\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "from typing import Optional, Union\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def adjust_distribution(p_, temperature):\n",
    "    # temperature cannot be 0\n",
    "    assert temperature != 0, 'Temperature cannot be 0'\n",
    "    p = np.array(p_)\n",
    "\n",
    "    print(p)\n",
    "    # If the temperature is very low (close to 0), then the sampling will become almost deterministic, picking the event with the highest probability.\n",
    "    # If the temperature is very high, then the sampling will be closer to uniform, with all events having roughly equal probability.\n",
    "\n",
    "    p = p / np.sum(np.abs(p))  # Normalizing the initial distribution\n",
    "    print(p)\n",
    "    print(temperature)\n",
    "    p = np.exp(p / temperature)\n",
    "    print('***')\n",
    "    print(p)\n",
    "    final_p = p / np.sum(p)  # Normalizing the final distribution\n",
    "    return final_p\n",
    "\n",
    "\n",
    "def sample(conditions: Union[pd.DataFrame, np.ndarray], temperature: float,\n",
    "                   samplers: list, params: dict,\n",
    "                   num_samples: Optional[int] = None) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "\n",
    "    Args:\n",
    "        conditions: pool of experimental conditions to evaluate: pd.Dataframe\n",
    "        temperature: how random is selection of conditions (cannot be 0; (0:1) - the choices are more deterministic than the choices made wrt\n",
    "        samplers: tuple containing sampler functions, their names, and weights\n",
    "        for sampler functions that return both positive and negative scores, user can provide a list with two weights: the first one will be applied to positive scores, the second one -- to the negative\n",
    "        params: nested dictionary. keys correspond to the sampler function names (same as provided in samplers),\n",
    "        values correspond to the dictionaries of function arguments (argument name: its value)\n",
    "        num_samples: number of experimental conditions to select\n",
    "\n",
    "    Returns:\n",
    "        Sampled pool of experimental conditions with the scores attached to them\n",
    "    \"\"\"\n",
    "\n",
    "    condition_pool = pd.DataFrame(conditions)\n",
    "\n",
    "    rankings = pd.DataFrame()\n",
    "    mixture_scores = np.zeros(len(condition_pool))\n",
    "    ## getting rankings and weighted scores from each function\n",
    "    for (function, name, weight) in samplers:\n",
    "        try:\n",
    "            sampler_params = params[name]\n",
    "            pd_ranking = function(conditions=condition_pool, **sampler_params)\n",
    "        except:\n",
    "            pd_ranking = function(conditions=condition_pool)\n",
    "        # sorting by index\n",
    "        pd_ranking = pd_ranking.sort_index()\n",
    "        # if only one weight is provided, use it for both negative and positive dimensions\n",
    "        if isinstance(weight, float) or isinstance(weight, int):\n",
    "            pd_ranking[\"score\"] = pd_ranking[\"score\"] * weight\n",
    "        else:\n",
    "            if len(pd_ranking[\"score\"] < 0) > 0 and len(pd_ranking[\"score\"] > 0) > 0:  # there are both positive and negative values\n",
    "\n",
    "                pd_ranking.loc[pd_ranking[\"score\"] > 0][\"score\"] = pd_ranking.loc[pd_ranking[\"score\"] > 0][\"score\"] * weight[0]  # positive dimension gets the first weight\n",
    "                pd_ranking.loc[pd_ranking[\"score\"] < 0][\"score\"] = pd_ranking.loc[pd_ranking[\"score\"] < 0][\"score\"] * weight[1]  # negative dimension gets the second weight\n",
    "            else:\n",
    "                pd_ranking[\"score\"] = pd_ranking[\"score\"] * weight[0]\n",
    "\n",
    "        pd_ranking.rename(columns={\"score\": f\"{name}_score\"}, inplace=True)\n",
    "        # sum_scores are arranged based on the original conditions_ indices\n",
    "        mixture_scores = mixture_scores + pd_ranking[f\"{name}_score\"]\n",
    "\n",
    "        rankings = pd.merge(rankings, pd_ranking, left_index=True, right_index=True, how=\"outer\")\n",
    "\n",
    "    # adjust mixture scores wrt temperature\n",
    "    weighted_mixture_scores_adjusted = adjust_distribution(mixture_scores, temperature)\n",
    "    print(weighted_mixture_scores_adjusted)\n",
    "\n",
    "    if num_samples is None:\n",
    "        num_samples = condition_pool.shape[0]\n",
    "\n",
    "    condition_indices = np.random.choice(np.arange(len(condition_pool)), num_samples,\n",
    "                                         p=weighted_mixture_scores_adjusted, replace=False)\n",
    "    conditions_ = condition_pool.iloc[condition_indices]\n",
    "    conditions_[\"score\"] = mixture_scores\n",
    "\n",
    "    return conditions_\n",
    "\n",
    "\n",
    "mixture_sample_test = sample"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [],
   "source": [
    "@on_state()\n",
    "def experimentalist_sample(conditions, models, experiment_data, variables, temperature, weights, num_samples):\n",
    "    print(models)\n",
    "    print(experiment_data)\n",
    "    if models is None or experiment_data is None:\n",
    "        print('First cycle: Using random sampler')\n",
    "        conditions_ = random_sample(conditions, num_samples)\n",
    "    else:\n",
    "        experiment_conditions = experiment_data[[v.name for v in variables.independent_variables]]\n",
    "        experiment_observations = experiment_data[[v.name for v in variables.dependent_variables]]\n",
    "        params_ = {} #copy.deepcopy(params)\n",
    "        params_[\"falsification\"] = {\"reference_conditions\": experiment_conditions, \"reference_observations\": experiment_observations, \"model\": models[-1]}\n",
    "        params_[\"novelty\"] = {\"reference_conditions\": experiment_conditions}\n",
    "\n",
    "\n",
    "        samplers = [\n",
    "            [novelty_score_sample, \"novelty\", weights[\"novelty\"]],\n",
    "            #[falsification_score_sample, \"falsification\", weights[\"falsification\"]]\n",
    "        ]\n",
    "        print(samplers)\n",
    "\n",
    "\n",
    "        conditions_ = mixture_sample_test(conditions, temperature, samplers, params_, num_samples)\n",
    "        conditions_ = conditions_.drop(\"score\", axis = 1)\n",
    "    #d = Delta(conditions=conditions)\n",
    "    d = Delta(conditions = conditions_)\n",
    "    return d"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-18T16:58:02.315542Z",
     "start_time": "2023-08-18T16:58:02.306342Z"
    }
   },
   "id": "2c29d738da9e6e0"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## BMS theorist\n",
    "Defining the BMS theorist and wrapping it into the state"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "eb2c0c9f94848d26"
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [],
   "source": [
    "@on_state()\n",
    "def bms_theorist(experiment_data: pd.DataFrame, variables: VariableCollection, **kwargs):\n",
    "    ivs = [v.name for v in variables.independent_variables]\n",
    "    dvs = [v.name for v in variables.dependent_variables]\n",
    "    X, y = experiment_data[ivs], experiment_data[dvs]\n",
    "    new_model = BMSRegressor(epochs=10).set_params(**kwargs).fit(X, y)\n",
    "    return Delta(models_bms=[new_model])\n",
    "\n",
    "@on_state()\n",
    "def linear_theorist(experiment_data: pd.DataFrame, variables: VariableCollection, **kwargs):\n",
    "    ivs = [v.name for v in variables.independent_variables]\n",
    "    dvs = [v.name for v in variables.dependent_variables]\n",
    "    X, y = experiment_data[ivs], experiment_data[dvs]\n",
    "    new_model = LinearRegression().set_params(**kwargs).fit(X, y)\n",
    "    return Delta(models_linear=[new_model])\n",
    "\n",
    "\n",
    "def PolynomialRegression(degree=3, **kwargs):\n",
    "    return make_pipeline(PolynomialFeatures(degree), LinearRegression(**kwargs))\n",
    "\n",
    "\n",
    "@on_state()\n",
    "def polynomial_theorist(experiment_data: pd.DataFrame, variables: VariableCollection, **kwargs):\n",
    "    ivs = [v.name for v in variables.independent_variables]\n",
    "    dvs = [v.name for v in variables.dependent_variables]\n",
    "    X, y = experiment_data[ivs], experiment_data[dvs]\n",
    "    new_model = PolynomialRegression()\n",
    "    new_model.fit(X, y)\n",
    "    return Delta(models_polynom=[new_model])\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "77ad50b2bc7fe0b2"
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [],
   "source": [
    "@on_state()\n",
    "def best_model(models_bms, models_linear, models_polynom, experiment_data, variables):\n",
    "    ivs = [v.name for v in variables.independent_variables]\n",
    "    dvs = [v.name for v in variables.dependent_variables]\n",
    "    X, y = experiment_data[ivs], experiment_data[dvs]\n",
    "    prediction_bms = models_bms[-1].predict(X)\n",
    "    prediction_linear = models_linear[-1].predict(X)\n",
    "    prediction_polynomial = models_polynom[-1].predict(X)\n",
    "    mad_bms = mean_absolute_error(y, prediction_bms)\n",
    "    mad_linear = mean_absolute_error(y, prediction_linear)\n",
    "    mad_poly = mean_absolute_error(y, prediction_polynomial)\n",
    "    if mad_bms <= mad_linear and mad_bms <= mad_poly:\n",
    "        new_model = models_bms[-1]\n",
    "    elif mad_linear <= mad_bms and mad_linear <= mad_poly:\n",
    "        new_model = models_linear[-1]\n",
    "    elif mad_poly <= mad_linear and mad_poly <= mad_bms:\n",
    "        new_model = models_polynom[-1]\n",
    "\n",
    "    return Delta(model=new_model)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [],
   "source": [
    "def cycle(s):\n",
    "    s_pool = experimentalist_pooler(s, equation=equation)\n",
    "    print(s_pool)\n",
    "    # s_conditions = experimentalist_sample(s_pool, temperature=TEMPERATURE, weights=WEIGHTS, num_samples=NUM_SAMPLES)\n",
    "    # s_run = runner_on_state(s_conditions)\n",
    "    # s_theory = bms_theorist(s_run)\n",
    "    # s_theory = linear_theorist(s_theory)\n",
    "    # s_theory = polynomial_theorist(s_theory)\n",
    "    # s_best = best_model(s_theory)\n",
    "    #return s_best\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'EquationTree' object has no attribute 'evaluate'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[49], line 3\u001B[0m\n\u001B[1;32m      1\u001B[0m state \u001B[38;5;241m=\u001B[39m ExtendedState(variables\u001B[38;5;241m=\u001B[39mvariables)\n\u001B[1;32m      2\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m _ \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;241m10\u001B[39m):\n\u001B[0;32m----> 3\u001B[0m     state \u001B[38;5;241m=\u001B[39m \u001B[43mcycle\u001B[49m\u001B[43m(\u001B[49m\u001B[43mstate\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      5\u001B[0m \u001B[38;5;28mprint\u001B[39m(state)\n",
      "Cell \u001B[0;32mIn[39], line 2\u001B[0m, in \u001B[0;36mcycle\u001B[0;34m(s)\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mcycle\u001B[39m(s):\n\u001B[0;32m----> 2\u001B[0m     s_pool \u001B[38;5;241m=\u001B[39m \u001B[43mexperimentalist_pooler\u001B[49m\u001B[43m(\u001B[49m\u001B[43ms\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mequation\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mequation\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      3\u001B[0m     \u001B[38;5;28mprint\u001B[39m(s_pool)\n",
      "File \u001B[0;32m~/Documents/GitHub/AutoResearch/autora-core/src/autora/state/__init__.py:1042\u001B[0m, in \u001B[0;36mdelta_to_state.<locals>._f\u001B[0;34m(state_, **kwargs)\u001B[0m\n\u001B[1;32m   1040\u001B[0m \u001B[38;5;129m@wraps\u001B[39m(f)\n\u001B[1;32m   1041\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_f\u001B[39m(state_: S, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m S:\n\u001B[0;32m-> 1042\u001B[0m     delta \u001B[38;5;241m=\u001B[39m \u001B[43mf\u001B[49m\u001B[43m(\u001B[49m\u001B[43mstate_\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1043\u001B[0m     \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(delta, Mapping), (\n\u001B[1;32m   1044\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mOutput of \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m must be a `Delta`, `UserDict`, \u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mor `dict`.\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m%\u001B[39m f\n\u001B[1;32m   1045\u001B[0m     )\n\u001B[1;32m   1046\u001B[0m     new_state \u001B[38;5;241m=\u001B[39m state_ \u001B[38;5;241m+\u001B[39m delta\n",
      "File \u001B[0;32m~/Documents/GitHub/AutoResearch/autora-core/src/autora/state/__init__.py:777\u001B[0m, in \u001B[0;36minputs_from_state.<locals>._f\u001B[0;34m(state_, **kwargs)\u001B[0m\n\u001B[1;32m    767\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (\n\u001B[1;32m    768\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mconditions\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01min\u001B[39;00m arguments\n\u001B[1;32m    769\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(arguments[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mconditions\u001B[39m\u001B[38;5;124m\"\u001B[39m], pd\u001B[38;5;241m.\u001B[39mDataFrame)\n\u001B[1;32m    770\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mvariables\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01min\u001B[39;00m [i\u001B[38;5;241m.\u001B[39mname \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m fields(state_)]\n\u001B[1;32m    771\u001B[0m ):\n\u001B[1;32m    772\u001B[0m     arguments[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mconditions\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m align_dataframe_to_ivs(\n\u001B[1;32m    773\u001B[0m         arguments[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mconditions\u001B[39m\u001B[38;5;124m\"\u001B[39m],\n\u001B[1;32m    774\u001B[0m         \u001B[38;5;28mgetattr\u001B[39m(state_, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mvariables\u001B[39m\u001B[38;5;124m\"\u001B[39m)\u001B[38;5;241m.\u001B[39mindependent_variables,\n\u001B[1;32m    775\u001B[0m     )\n\u001B[0;32m--> 777\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[43mf\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43marguments\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    778\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m result\n",
      "Cell \u001B[0;32mIn[45], line 7\u001B[0m, in \u001B[0;36mexperimentalist_pooler\u001B[0;34m(variables, equation)\u001B[0m\n\u001B[1;32m      5\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m i \u001B[38;5;241m<\u001B[39m \u001B[38;5;241m1_000_000\u001B[39m \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(conditions_\u001B[38;5;241m.\u001B[39mindex) \u001B[38;5;241m<\u001B[39m NUM_POOL_SAMPLES:\n\u001B[1;32m      6\u001B[0m     _sample \u001B[38;5;241m=\u001B[39m random_pool(variables, \u001B[38;5;241m1\u001B[39m)\n\u001B[0;32m----> 7\u001B[0m     evaluation \u001B[38;5;241m=\u001B[39m \u001B[43mequation\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mevaluate\u001B[49m(_sample)\n\u001B[1;32m      8\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m np\u001B[38;5;241m.\u001B[39misnan(evaluation)\u001B[38;5;241m.\u001B[39many() \u001B[38;5;129;01mor\u001B[39;00m np\u001B[38;5;241m.\u001B[39misinf(evaluation)\u001B[38;5;241m.\u001B[39many():\n\u001B[1;32m      9\u001B[0m         i\u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m\n",
      "\u001B[0;31mAttributeError\u001B[0m: 'EquationTree' object has no attribute 'evaluate'"
     ]
    }
   ],
   "source": [
    "state = ExtendedState(variables=variables)\n",
    "for _ in range(10):\n",
    "    state = cycle(state)\n",
    "\n",
    "print(state)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
