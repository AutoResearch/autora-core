{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear And Cyclical Workflows Using Functions And States"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the functions and objects in `autora`, we can build flexible pipelines and cycles."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment Runner And Theorist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define a two part AER pipeline consisting of an experiment runner and a theorist (we use the seed conditions\n",
    "always).\n",
    "\n",
    "The key part here is that both experiment runner and theorist are functions which:\n",
    "- operate on the `State`, and\n",
    "- return a modified object of the **same type** `State`.\n",
    "\n",
    "### Defining The State\n",
    "\n",
    "We use the standard State object bundled with `autora`: `StandardState`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from autora.variable import VariableCollection, Variable\n",
    "from autora.state import StandardState\n",
    "\n",
    "s = StandardState(\n",
    "    variables=VariableCollection(independent_variables=[Variable(\"x\", value_range=(-15,15))],\n",
    "                                 dependent_variables=[Variable(\"y\")]),\n",
    "    conditions=pd.DataFrame({\"x\": np.linspace(-15,15,101)}),\n",
    "    experiment_data = pd.DataFrame(columns=[\"x\",\"y\"]),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given this state, we define a two part AER pipeline consisting of an experiment runner and a theorist. We'll just\n",
    "reuse the initial seed `conditions` in this example.\n",
    "\n",
    "First we define and test the experiment runner.\n",
    "\n",
    "The key part here is that both the experiment runner and the theorist are functions which operate on the `State`.\n",
    "We use the wrapper function `wrap_to_use_state` that wraps the experiment_runner and makes it operate on the\n",
    "fields of the `State` rather than the `conditions` and `experiment_data` directly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining The Experiment Runner\n",
    "\n",
    "For this example, we'll use a polynomial of degree 3 as our \"ground truth\" function. We're also using pandas\n",
    "DataFrames and Series as our data interchange format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autora.state import on_state, Delta\n",
    "\n",
    "def ground_truth(x: pd.Series, c=(432, -144, -3, 1)):\n",
    "    return c[0] + c[1] * x + c[2] * x**2 + c[3] * x**3\n",
    "\n",
    "@on_state\n",
    "def experiment_runner(conditions, std=100., random_state=None):\n",
    "    \"\"\"Coefs from https://www.maa.org/sites/default/files/0025570x28304.di021116.02p0130a.pdf\"\"\"\n",
    "    rng = np.random.default_rng(random_state)\n",
    "    x = conditions[\"x\"]\n",
    "    noise = rng.normal(0, std, len(x))\n",
    "    y = (ground_truth(x) + noise)\n",
    "    experiment_data = conditions.assign(y = y)\n",
    "    return Delta(experiment_data=experiment_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we run the experiment runner, we can see the updated state object which is returned – it has new experimental data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_runner(s, std=1).experiment_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining The Theorist\n",
    "\n",
    "Now we define a theorist, which does a linear regression on the polynomial of degree 5. We define a regressor and a\n",
    "method to return its feature names and coefficients, and then the theorist to handle it. Here, we use a different wrapper `estimator_on_state` that wraps the regressor and returns a function with the same functionality, but operating on `State` fields. In this case, we want to use the `State` field `experiment_data` and extend the `State` field `models`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from autora.state import estimator_on_state\n",
    "from sklearn.pipeline import make_pipeline as make_theorist_pipeline\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "# Completely standard scikit-learn pipeline regressor\n",
    "regressor = make_theorist_pipeline(PolynomialFeatures(degree=5), LinearRegression())\n",
    "theorist = estimator_on_state(regressor)\n",
    "\n",
    "def get_equation(r):\n",
    "    t = r.named_steps['polynomialfeatures'].get_feature_names_out()\n",
    "    c = r.named_steps['linearregression'].coef_\n",
    "    return pd.DataFrame({\"t\": t, \"coefficient\": c.reshape(t.shape)})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Directly Chaining State Based Functions\n",
    "\n",
    "Now we run the theorist on the result of the experiment runner (by chaining the two functions)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = theorist(experiment_runner(s, random_state=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The fitted coefficients are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_equation(t.model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating A Pipeline With State Based Functions\n",
    "\n",
    "Now we can define the simplest pipeline which runs the experiment runner and theorist in sequence and returns the\n",
    "updated state:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline(state: StandardState, random_state=None) -> StandardState:\n",
    "    s_ = state\n",
    "    t_ = experiment_runner(s_, random_state=random_state)\n",
    "    u_ = theorist(t_)\n",
    "    return u_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running this pipeline is the same as running the individual steps – just pass the state object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u = pipeline(s, random_state=1)\n",
    "get_equation(u.model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the pipeline function operates on the `State` itself and returns a `State`, we can chain these pipelines in the same fashion as we chain the theorist and experiment runner:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u_ = pipeline(pipeline(s, random_state=1), random_state=2)\n",
    "get_equation(u_.model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To show what's happening, we'll show the data, best fit model and ground truth:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "def show_best_fit(state):\n",
    "    state.experiment_data.plot.scatter(\"x\", \"y\", s=1, alpha=0.5, c=\"gray\")\n",
    "\n",
    "    observed_x = state.experiment_data[[\"x\"]].sort_values(by=\"x\")\n",
    "    observed_x = pd.DataFrame({\"x\": np.linspace(observed_x[\"x\"].min(), observed_x[\"x\"].max(), 101)})\n",
    "\n",
    "    plt.plot(observed_x, state.model.predict(observed_x), label=\"best fit\")\n",
    "    \n",
    "    allowed_x = pd.Series(np.linspace(*state.variables.independent_variables[0].value_range, 101), name=\"x\")\n",
    "    plt.plot(allowed_x, ground_truth(allowed_x), label=\"ground truth\")\n",
    "    \n",
    "    plt.legend()\n",
    "\n",
    "def show_coefficients(state):\n",
    "    return get_equation(state.model)\n",
    "\n",
    "show_best_fit(u)\n",
    "show_coefficients(u)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use this pipeline to make a trivial cycle, where we keep on gathering data until we reach 1000 datapoints. Any\n",
    " condition defined on the state object could be used here, though."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = s\n",
    "while len(v.experiment_data) < 1_000:  # any condition on the state can be used here.\n",
    "    v = pipeline(v)\n",
    "show_best_fit(v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Generators With State Based Functions\n",
    "\n",
    "We can redefine the pipeline as a generator, which can be operated on using iteration tools:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cycle(state: StandardState) -> StandardState:\n",
    "    s_ = state\n",
    "    while True:\n",
    "        s_ = experiment_runner(s_)\n",
    "        s_ = theorist(s_)\n",
    "        yield s_\n",
    "\n",
    "cycle_generator = cycle(s)\n",
    "\n",
    "for i in range(1000):\n",
    "    t = next(cycle_generator)\n",
    "show_best_fit(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also define a cycle (or a sequence of steps) which yield the intermediate results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v0 = s\n",
    "def cycle(state: StandardState) -> StandardState:\n",
    "    s_ = state\n",
    "    while True:\n",
    "        print(\"#-- running experiment_runner --#\\n\")\n",
    "        s_ = experiment_runner(s_)\n",
    "        yield s_\n",
    "        print(\"#-- running theorist --#\\n\")\n",
    "        s_ = theorist(s_)\n",
    "        yield s_\n",
    "\n",
    "cycle_generator = cycle(v0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At the outset, we have no model and an emtpy `experiment_data` dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"{v0.model=}, \\n{v0.experiment_data=}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the first `next`, we only run the \"experiment_runner\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v1 = next(cycle_generator)\n",
    "print(f\"{v1.model=}, \\n{v1.experiment_data=}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next step, we run the theorist on that data, but we don't add any new data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v2 = next(cycle_generator)\n",
    "print(f\"{v2.model=}, \\n{v2.experiment_data.shape=}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next step, we run the experiment runner again and gather more observations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v3 = next(cycle_generator)\n",
    "print(f\"{v3.model=}, \\n{v3.experiment_data.shape=}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding The Experimentalist\n",
    "\n",
    "Modifying the code to use a custom experimentalist is simple. We define an experimentalist which adds some observations\n",
    "each cycle:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autora.experimentalist.random import random_pool\n",
    "experimentalist = on_state(random_pool, output=[\"conditions\"])\n",
    "experimentalist(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u0 = s\n",
    "for i in range(5):\n",
    "    u0 = experimentalist(u0, num_samples=10, random_state=42+i)\n",
    "    u0 = experiment_runner(u0, random_state=43+i)\n",
    "    u0 = theorist(u0)\n",
    "    show_best_fit(u0)\n",
    "    plt.title(f\"{i=}, {len(u0.experiment_data)=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
